\chapter{Zientzia konputazioa.}

\section{Sarrera.}

Gaur-egun, orokorrean konputagailuak (super-konputagailu, eramangarri,...) paraleloak dira. 1986-2002 urteen artean,  prozesadore bakarreko konputagailuen eraginkortasuna hobetuz joan zen, txipean transistore dentsitatea handitzen zen heinean   baina teknologi-garapena muga fisikoetara iritsita, bide honetatik konputagailuen abiadura hobetzea ezinezkoa bilakatu zen. Horrela, 2005.urtetik aurrera fabrikatzaileek konputagailuen gaitasuna hobetzeko, txipan prozesadore bat baino gehiago erabiltzea erabaki zuten.      

\paragraph*{Moore's Law (1965)}. Processor speed doubles every 18 months.
\paragraph*{Moore's Law Reinterpreter}. Number of cores per chip can double every two years.

\begin{figure}[h]
\centerline{\includegraphics[width=10cm, height=6cm] {ProcessorClock}}
\caption[Processor clock rate.]{Processor clock rate growth halted around 2005.}
\label{fig:61}
\end{figure} 


\begin{figure}[h]
\centerline{\includegraphics[width=12cm, height=8cm] {PerformanceDevelopment}}
\caption[Konputagailuen eraginkortasuna.]{www.top500.org, Top: total computing power of top 500 computers. Middle: 1 computer. Bottom: 500 computer.}
\label{fig:61}
\end{figure} 

\paragraph*{} Konputagailuen eredu aldaketa honen ondorioz, algoritmo azkarrak garatzeko kodearen paralelizazio gaitasunari heldu behar zaio. Beraz programazio paralelo teknikak inplementatzeko, beharrezko da prozesadore berrien hardware arkitekturak nahiz software ingurune berriak ulertzea. Gaia nahiko konplexua izanik, ikuspegi orokorra eman ondoren, gure inplementazioan erabilitako hardware arkitektura eta software teknika zehatzak azalduko ditugu. Memoria-konpartitutako sistemak eta OpenMP programazio eredua deskribatuko dugu.

\paragraph*{}Bi dira, algoritmo azkarrak diseinatzeko erronkak: 
\begin{enumerate}
\item Paralizatzeko pisuko lana identifikatzea.
\item Memoria eta prozesadorearen arteko datu mugimendua gutxitzea. 
\end{enumerate}

\paragraph*{}Bestalde, inplementazio berrien garapenean optimizatutako liburutegiak erabiltzea komeni da. Horien artean, LAPACK eta BLAS algebra linealeko liburutegiak erabilgarriak izan zaizkigu. Liburutegi hauen gaineko azalpenak emango ditugu.

\section{Parallel Hardware.}

\subsection*{\textbf{Zein azkarrak dira konputagailuak?}}

\paragraph*{}Gaur egungo prozesadoreen abiadura Gigahertzioetan neurtzen da. 

\begin{itemize}
\item Kilo = mila ($10^3$).
\item Mega = milioi ($10^6$).
\item Giga = bilioi ($10^9$).
\item Tera = trilioi ($10^{12}$).
\item Peta = $10^{15}$.
\item Exa = $10^{18}$. 
\end{itemize}

\paragraph*{} Hertzioak "makina zikloak segunduko" esan nahi du. Koma-higikorrezko  eragiketa bat egiteko ($\oplus,\ominus,\otimes,\oslash$) ziklo gutxi batzuk behar dira. Honek esan nahi du, $1$GHz-ko prozesagailu batek,
$>100.000.000$ koma-higikorrezko eragiketa segunduko egiten dituela ($>100$ Megaflops).

\paragraph*{\textbf{Adibidea}}. 
$C=AB$ matrize-matrize biderketa.

\paragraph*{}Demagun $A,B$ eta $C \ (n \times n)$ dimentsioko matrizeak.

\begin{equation*}
c_{ij}=\sum\limits_{i,j=1}^{n} a_{ij}*b_{ji}
\end{equation*}

\paragraph*{} $c_{ij}$ gai bakoitza kalkulatzeko $n$ biderketa eta ($n-1$) batura egin behar ditugu.

$C$ matrizeak $n^2$ osagaia ditu $\Rightarrow$ $O(n^3)$ koma-higikorrezko ariketak.

$n=1000 \ \Rightarrow \ n^3=10^{12}$

$>1000$ segundu $1$GHz prozesagailuan.

\paragraph*{} Zientzia konputazioaren eraginkortasuna neurtzeko, koma-higikorrezko eragiketa kopurua (flops) erabiltzen zen. Problema handia denean, datuen mugimendua koma-higikorrezko eragiketak baino garestiagoa da, eta beraz eraginkortasuna aztertzeko koma-higikorrezko eragiketa kopurua neurtzea okerra izan daiteke. Kodearen exekuzioa azkartzeko derrigorrezkoa da konputagailuan datuen mugimendua minimizatzea.

\subsection*{\textbf{Memoria Hierarkia.}}

\paragraph*{}Lehenik, konputagailuan dauden memoria mota ezberdinen hierarkia azalduko dugu. 

\begin{figure}[h]
\centerline{\includegraphics[width=10cm, height=4cm] {MemoryHierarchy}}
\caption{Memoria hierarkia.}
\label{fig:three}
\end{figure} 

\paragraph*{} CPU-k koma-higikorrezko eragiketak egiten ditu: datuak erregistroetatik irakurri, eragiketa egin eta emaitza erregistroetan idazten ditu. Memoria nagusia eta erregistroen artean, 2 edo 3 mailako Cache memoria dugu: lehen Cache memoria (L1) txikiena eta azkarrena da, eta beste mailak (L2,L3,...), handiagoak eta motelagoak. Memoria nagusian, exekutatzen diren programak eta datuak gordetzen dira ($1-4$ GB artekoa). Azkenik, disko gogorrean konputagailuko datu (argazki, bideo,...) eta erabilgarri ditugun programa guztiak gordetzen dira.  
   
\paragraph*{} Cache memorian, programak hurrengo unean behar dituen datuak gertu dauden printzipioaren arabera gordetzen da informazioa. Cache memoria blokeka (line) egituratuta dago eta bloke bakoitza $64$ edo $128$ bytez ($8$ edo $16$ double zenbaki) osatuta dago. 

\paragraph*{\textbf{Adibidea}}. Badakigunez, C-lengoaian matrizeak lerroka gordetzen dira. Beheko adibidean,  matrizearen lehen osagaia $a(1,1)$ behar dugunean, memoria nagusitik Cachera osagai honetaz gain jarraiko 16 osagaiak ekarriko dira ($a(1,1),a(1,2),\dots,a(1,16)$). Honela, hurrengo $15$ batura egiteko behar ditugun datuak Cachean eskuara izango ditugu memoria irakurketa berririk egin gabe. 

\begin{algorithm}[h]
 \BlankLine
  $int \ n$\;
  $double \ a[n][n]$\;
  \BlankLine
  $sum=0$\;
  \For{$i\leftarrow 1$ \KwTo $n$}
  {
   \BlankLine
    \For{$j\leftarrow 1$ \KwTo $m$}
   {
    \BlankLine 
    $sum+=a(i,j)$\;
   }
 }
 \caption{Main Algorithm}
\end{algorithm} 

\begin{equation*}
a=\left(\begin{array}{ccccc}
  1    & 2    & 3    & \dots & 1000 \\
  1001 & 1002 & 1003 &\dots & 2000 \\
  2001 & 2002 & 2003 &\dots & 2000 \\
  \dots & \dots & \dots & \dots & \dots \\
  9001 & 9002 & 9003 &\dots & 10000 \\
  \end{array}\right).  
\end{equation*}

\paragraph*{}CPUk datu bat behar duenean, memoria hierarkian zehar bilatuko du: lehenik $L1$ cachean, ondoren $L2$ cachean,...eta hauetan ez badago, memoria nagusira joko du. Memoria nagusi eta cache memoria arteko irakurketa eta idazketa guzti hauetan,  informazio konsistentzia mantentzeko hainbat arau aurrera ematen dira.  

\subsection*{\textbf{Hardware.}}

MIMD (Multiple instruction, multiple data) sistemak, guztiz independienteak diren prozesadore multzoak osatzen dituzte. Bi dira MIMD sistema nagusiak: memoria konpartitutako eta memoria distribuitutako sistemak. Memoria konpartitutako sistemetan, prozesadore guztiek memoria osoa konpartitzen dute eta inplizituki konpartitutako datuen atzipenaren bidez komunikatzen dira. Memoria distribuitutako sistemetan aldiz, prozesadore bakoitzak bere memoria pribatua du eta explizituki bidalitako mezuen bidez komunikatzen dira.

\paragraph*{} Hirugarren hardware arkitektura ere aipatuko dugu, general purpose GPU computing (Graphical Processor Unit).
Jokuen eta animazio industriak, grafiko oso azkarrak beharrak biltzatuta  sortutako teknologia da. Oinarrian, imaginak oantailaratzeko prozesagailu asko paraleloan lan egiten dute. Azken hamarkadan, GPU unitate hauek zientzia konputaziora zabaldu dira.  

\begin{figure}[h]
\centerline{\includegraphics[width=12cm, height=4cm] {SharedMemorySystem}}
\caption{Shared Memory System.}
\label{fig:61}
\end{figure}  

\begin{figure}[h]
\centerline{\includegraphics[width=12cm, height=4cm] {DistribuitedMemorySystem}}
\caption{Distribuited Memory System.}
\label{fig:61}
\end{figure}  

\paragraph*{\textbf{Shared-memory systems}}. Multicore bat edo gehiagoz osatutako sistema dugu. Multicore prozesadore bakoitzak txipean CPU bat baino gehiago ditu. Normalean CPU bakoitzak $L1$ bere cache memoria du. Aipatzeko da, era honetako sistemetan prozesadore kopurua ezin dela nahi adina handitu eta mugatua dela (normalean $\leq 32$ ).

 \begin{figure}[h]
 \centerline{\includegraphics[width=12cm, height=4cm] {SharedMemorySystemUMA}}
 \caption{Shared Memory System (UMA).}
 \label{fig:61}
 \end{figure}  

\subsection*{\textbf{Sofwarea.}}

C-lengoaia programazio paraleloan erabiltzeko, lengoiaren bi extensio dira nagusienak: bata memori-distribuitutako sistemetarako diseinatuta  MPI (Message-Passing Inteface) eta bestea, memoria-konpartitutako sistemetarako diseinutakoa OpenMP (Open Specifications for MultiProcessing). MPI datu moten definizio, funtzio eta makroen liburegia da. OpenMP liburutegia bat  eta C konpiladorearen aldaketa batzuk. OpenMP erabili dugu gure inplementaziorako eta jarraian honi buruzko idei nagusienak emango ditugu.

\paragraph*{\textbf{OpenMP}}. Memoria konpartitutako programazio paraleloaren estandarra dugu. 
Programazioan paralelizazio kontrola, "fork-join" modeloa jarraituz egiten da.

\begin{enumerate}
\item OpenMP programen hasieran prozesu bakarra dago, hari (thread) nagusia. 
\item FORK: hari nagusiak hari talde paraleloa sortzen du.
\item JOIN: hariak kode paraleloa bukatzen dutenean, behin sinkronizatuta amaitzen dute eta hari nagusiak bakarrik jarraitzen du.
\end{enumerate}

% \begin{figure}[h]
% \centerline{\includegraphics[width=10cm, height=3cm] {ForkJoin}}
% \caption{Fork-Join.}
% \label{fig:61}
% \end{figure}  
 
 \begin{figure}[h]
 \centering
 \subfloat[Fork-Join.]{
 \includegraphics[width=.500\textwidth]{ForkJoin}
 }
 \subfloat[Fork-Join.]{
 \includegraphics[width=.200\textwidth]{OpenMP1}
 }
  \caption[OpenMp programming model.]{\small OpenMp programming model..}
 \label{fig:forkjoin}
 \end{figure}

Aldagai batean (threadcount) paralelizazioan zenbat hari erabili adierazten da eta ohikoa izaten da hari bat prozesadore bakoitzeko sortzea.  Konpilazio direktiben bidez,  paralelizazioa nola exekutatu behar den zehazten zaio.

\paragraph*{\textbf{Adibidea}}.

\begin{lstlisting}
#    pragma omp parallel for num_threads(thread_count) 
     for (i = 0; i<n; i++)
     {
       ! Aginduak 
     }
\end{lstlisting}

OpenMP Version 4.5.	

gcc -v (gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3))


\section{Software liburutegiak.}

Matematika bi software errekurtso nagusienak aipatuko ditugu; BLAS (Basic Linear Algebra Subroutines) eta LAPACK (Linear Algebra Package). Kalitate handiko software orokorrak dira eta hauek erabiltzea abantaila asko ditu: 

\begin{enumerate}
\item Garapen berriak egiteko denbora aurrezten du. 
\item Problema askotan ondo probatutako softwareak dira.
\item Konplexutasun handikoak dira, modu seguruan eta azkarrean exekutatzeko disenatu direlako. 
\end{enumerate}

Konputagailu hardware bakoitzerako optimizatutako bertsioak daude. Inplementazioa Fortranen egina dago eta datu-motei dagokionez:

\begin{enumerate}
\item S: float ($32$ bit).
\item D: double ($64$ bit).
\item C: complex.
\item Z: complex double.
\end{enumerate}   

\subsection*{\textbf{BLAS}}.

BLAS liburutegian, bektore eta matrizeen arteko funtzio estandarrak inplementatuta daude. Hiru mailetan banatuta dago: 

\begin{enumerate}
\item BLAS-1: bektore-bektore eragiketak.

 Adibidez: $y=\alpha*x+y$ , $2n$ flop eta $3n$ irakurketa/idazketa.
 
 Konputazio intentsitatea: $\frac{2n}{3n}=\frac{2}{3}$. 

\item BLAS-2: matrize-bektore eragiketak.

 Adibidez: $y=\alpha*A*x+\beta*x$, $O(n^2)$ flop eta $O(n^2)$ irakurketa/idazketa.
 
 Konputazio intentsitatea: $\approx \frac{2n^2}{n^2}=2$. 
 
\item BLAS-3: matrize-matrize eragiketak.

 Adibidez: $C=\alpha*A*B+\beta*C$, $O(n^3)$ flop eta $O(n^2)$ irakurketa/idazketa.
 
 Konputazio intentsitatea: $\approx \frac{2n^3}{4n^2}=\frac{n}{2}$. 

\end{enumerate}

Azpimarratu, BLAS-1 eta BLAS-2 funtzioen konputazio intetsitatea txikia dela eta beraz, datuen komunikazioa nagusia dela. BLAS-3 aldiz, konputazio intentsitatea handiagoa da eta eazugarri honi esker, konputagailuaren konputazio gaitasuna ondo aprobetxatu ahal izango da.

\begin{figure}[h]
\centerline{\includegraphics[width=12cm, height=8cm] {BLASSpeed}}
\caption{BLAS speeds.}
\label{fig:61}
\end{figure}    

Fabrikatzaile bakoitzak optimizatutako BLAS liburutegiak (AMD ACML,Intel MKL) dituzte eta beraz, multi-threaded dira.
Beste aukera bat, optimizatutako BLAS instalazioa ATLAS (Automatically Tuned Linear Algebra Software) bidez egitea.    

\subsection*{\textbf{LAPACK}}.

Zenbakizko algebra linealaren liburutegia da.

\begin{enumerate}
\item Sistema linealak: $AX=b$.
\item Least Square: choose $x$ to minimize $\|Ax-b\|$.
\item Eigenvalues.
\item Balio singularren deskonposaketa (SVD).
\end{enumerate}

Posible den guztietan, BLAS-3 funtzioetan oinarritzen da.

\section{Kode Optimizazioak.}

Applications have two general challenges:
\begin{enumerate}
\item Numerical Method.

Performance required computation the shortest account of time.

\item. Computer Program.

Express the algorithm as fast computer problem, you have realized computer hardware eficiently.

\end{enumerate}

Optimization areas are:
\begin{enumerate}
\item Vectorization.
\item Paralelization.
\item Memory trafic control.
\end{enumerate}

Optimization areas:
\begin{enumerate}
\item scalar optimization (compiler friendly practices).

\item vectorization (must use 16 or 8 wide vectors).

\item multi-threading (must  scale to $100+$ threads).

\item memory access (streaming acces).

\item communication (offload, MPI traffic control).

\end{enumerate}


\subsection{Scalar Tuning and General Optimization.}

Optimization of scalar arithmetics.

One of the most important scalar optimizazion techincs is  \textbf{strength reduction} : replace expensive operation for less expensive operations.

\begin{figure}[h]
 \centerline{\includegraphics[width=12cm, height=4cm] {Optimization_Strength_Reduction}}
 \caption{Optimization.}
 \label{fig:61}
\end{figure}  

\paragraph*{} Precision control.

\begin{enumerate}
\item Precision Control for transcendental functions.

\item Floating-point semantics.

\item Consistency of precision: constants and constants.

Using incorrect function names in the single precsion is a common mistake

\end{enumerate}

\subsection{Optimization of vectorization.}

\begin{enumerate}

\item Preferably unid-stride access to data.
Very important step in the optimization.

Artikulua "Auto-Vectorization with the Intel Compilers".

Most CPU architectures today include Single Instruction Multiple Data (SIMD) parallelism in the form
of a vector instruction set. Serial codes (i.e., running with a single thread), as well as instruction-parallel cal-
culations (running with several threads) can take advantage of SIMD instructions and significantly increase
the performance of some computations. Each CPU core performs SIMD operations on several numbers (in-
tegers, single or double precision floating-point numbers) simultaneously, when these variables are loaded
into the processor’s vector registers, and a vector instruction is applied to them. SIMD instructions include
common arithmetic operations (addition, subtraction, multiplication and division), as well as comparisons,
reduction and bit-masked operations (see, e.g., the list of SSE 2 intrinsics). Libraries such as the Intel Math
Library provide SIMD implementations of common transcendental functions, and other libraries provide
vectorized higher-level operations for linear algebra, signal analysis, statistics, etc.

\item Data Alignment and Padding.

An important consideration for efficient vectorization is data alignment.


\end{enumerate}

\subsection{Multi-threading.}

Do you have enough parallelism in your code? 

Expanding iteration space, if it is no enough iterations in parallel loop.

Three layers of parallelism: MPI processes, OpenMP threads, vectorization.


\subsection{Memory access.}

Memory access and Cache utilization.

loop tiling technics

\begin{figure}[h]
 \centerline{\includegraphics[width=12cm, height=4cm] {Optimization_LoopTiling}}
 \caption{Optimization.}
 \label{fig:61}
\end{figure}  

\section{Laburpena.}

Best practices for code vectorization and parallelization, and additional tips and tricks.

Algoritmo bat inplementatzen dugunean kontutan hartu beharrekoa:

\begin{enumerate}

\item Lerro edo zutabe araberako iterazioak exekuzio denboran eragin handia du.

\item Kodea garbia eta ulergarria mantendu behar da.

\item Badaude kodearen exekuzio denboraren analisia egiteko tresnak (adibidez gprof). Algoritmoaren funtzio bakoitzaren exekuzio denborari buruzko informazio erabilgarria lortuko dugu. Zenbait gauza modu sinplean azkartu daitezke baina zenbait beste gauza azkartzeko esfuertzu handia eskatu dezake.

\item Optimizatutako beste hainbat kode erabiltzea komenigarria da. LAPACK aljebra lineal paketea Fortran eta C-lengoaitetatik deitu daiteke. Eraberean, LAPACKek BLAS subrutinak erabiltzen ditu.  Subrutinak hauek matrizen arteko biderketak, "inner product", ... BLAS konputagailu arkitektura ezberdinetarako optimizatutako bertsioak daude.
 

\end{enumerate}

